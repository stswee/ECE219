{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import time\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, ShuffleSplit, GridSearchCV\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay\n",
        "from sklearn.decomposition import TruncatedSVD, NMF\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import re\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, CountVectorizer\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "from statsmodels.stats.contingency_tables import mcnemar\n",
        "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set random seeds\n",
        "np.random.seed(42)\n",
        "random.seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyjhYyhPJeb4",
        "outputId": "0382180f-532f-4448-c096-c156b73f68b5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing functions\n",
        "def clean(text) -> str:\n",
        "  \"\"\"\n",
        "  Processes the text based on rules.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  text : str\n",
        "    The string to process.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  str\n",
        "    The processed string.\n",
        "  \"\"\"\n",
        "  text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
        "  texter = re.sub(r\"<br />\", \" \", text)\n",
        "  texter = re.sub(r\"&quot;\", \"\\\"\",texter)\n",
        "  texter = re.sub('&#39;', \"\\\"\", texter)\n",
        "  texter = re.sub('\\n', \" \", texter)\n",
        "  texter = re.sub(' u ',\" you \", texter)\n",
        "  texter = re.sub('`',\"\", texter)\n",
        "  texter = re.sub(' +', ' ', texter)\n",
        "  texter = re.sub(r\"(!)\\1+\", r\"!\", texter)\n",
        "  texter = re.sub(r\"(\\?)\\1+\", r\"?\", texter)\n",
        "  texter = re.sub('&amp;', 'and', texter)\n",
        "  texter = re.sub('\\r', ' ',texter)\n",
        "  clean = re.compile('<.*?>')\n",
        "  texter = texter.encode('ascii', 'ignore').decode('ascii')\n",
        "  texter = re.sub(clean, '', texter)\n",
        "  if texter == \"\":\n",
        "    texter = \"\"\n",
        "  return texter\n",
        "\n",
        "def remove_numbers(text = str) -> str:\n",
        "  \"\"\"\n",
        "  Removes numbers from the text.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  text : str\n",
        "    The string to remove numbers from.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  str\n",
        "    The string with numbers removed.\n",
        "  \"\"\"\n",
        "\n",
        "  # Remove numbers\n",
        "  return re.sub(r'\\b\\d+\\b', '', text)\n",
        "\n",
        "def remove_punctuation(text = str) -> str:\n",
        "  \"\"\"\n",
        "  Removes punctuation from the text.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  text : str\n",
        "    The string to remove punctuation from.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  str\n",
        "    The string with punctuation removed.\n",
        "  \"\"\"\n",
        "\n",
        "  # Remove punctuation\n",
        "  return re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "def lemmatize(text = str) -> str:\n",
        "  \"\"\"\n",
        "  Lemmatizes the text.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  text : str\n",
        "    The string to lemmatize.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  str\n",
        "    The lemmatized string.\n",
        "  \"\"\"\n",
        "\n",
        "  # Helper function for part of speech\n",
        "  def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "\n",
        "  # Initialize lemmatizer\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "  # Get tokens\n",
        "  words = text.split()\n",
        "\n",
        "  # Get part of speech\n",
        "  pos_tags = pos_tag(words)\n",
        "\n",
        "  # Lemmatize each word\n",
        "  words_lemmatize = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
        "\n",
        "  # Join words back together\n",
        "  return \" \".join(words_lemmatize)\n",
        "\n",
        "def stemming(text = str) -> str:\n",
        "  \"\"\"\n",
        "  Stems the text.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  text : str\n",
        "    The string to stem.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  str\n",
        "    The stemmed string.\n",
        "  \"\"\"\n",
        "\n",
        "  # Initialize stemmer\n",
        "  stemmer = PorterStemmer()\n",
        "\n",
        "  # Get tokens\n",
        "  words = text.split()\n",
        "\n",
        "  # Stem each word\n",
        "  words_stem = [stemmer.stem(word) for word in words]\n",
        "\n",
        "  # Join words back together\n",
        "  return \" \".join(words_stem)\n",
        "\n",
        "def preprocessing(df = pd.DataFrame, preprocessing_functions = list) -> pd.DataFrame:\n",
        "  \"\"\"\n",
        "  Preprocesses the text in the dataframe.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  df : pd.DataFrame\n",
        "    The dataframe to preprocess.\n",
        "  preprocessing_functions : list\n",
        "    The list of preprocessing functions to apply.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  pd.DataFrame\n",
        "    The preprocessed dataframe.\n",
        "  \"\"\"\n",
        "\n",
        "  # Initialize dataframe\n",
        "  df_copy = df.copy()\n",
        "\n",
        "  # Apply preprocessing functions\n",
        "  for preprocessing_function in preprocessing_functions:\n",
        "    df_copy.map(preprocessing_function)\n",
        "\n",
        "  return df_copy"
      ],
      "metadata": {
        "id": "DnRPY96MJtOo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation functions\n",
        "\n",
        "def classifier_metrics(y_true = list, y_pred = list, model_name = \"Model\"):\n",
        "  \"\"\"\n",
        "  Prints the metrics for a classifier.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  y_true : list\n",
        "    The true labels.\n",
        "  y_pred : list\n",
        "    The predicted labels.\n",
        "  model_name : str\n",
        "    The name of the model.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  None\n",
        "  \"\"\"\n",
        "\n",
        "  # Print metrics\n",
        "  print(model_name)\n",
        "  print(\"Accuracy: \", accuracy_score(y_true, y_pred))\n",
        "  print(\"Precision: \", precision_score(y_true, y_pred, pos_label = 'sports'))\n",
        "  print(\"Recall: \", recall_score(y_true, y_pred, pos_label = 'sports'))\n",
        "  print(\"F1 score: \", f1_score(y_true, y_pred, pos_label = 'sports'))\n",
        "  print()\n",
        "\n",
        "def plot_roc_curve(y_true = list, y_pred_prob = list, model_name = \"Model\"):\n",
        "  \"\"\"\n",
        "  Plots the ROC curve for a binary classifier.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  y_true : list\n",
        "      The true labels.\n",
        "  y_pred_prob : list\n",
        "      The predicted probabilities.\n",
        "  model_name : str\n",
        "      The name of the model.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  None\n",
        "  \"\"\"\n",
        "\n",
        "  # Binarize string labels\n",
        "  lb = LabelBinarizer(pos_label = 1)\n",
        "  y_true = lb.fit_transform(y_true)\n",
        "\n",
        "  # Compute the ROC curve and AUC score\n",
        "  fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
        "  roc_auc = auc(fpr, tpr)\n",
        "\n",
        "  # Plot the ROC curve\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.plot(fpr, tpr, color = 'blue', lw = 2, label = f\"{model_name} (AUC = {roc_auc:.2f})\")\n",
        "  plt.plot([0, 1], [0, 1], color = 'black', lw = 2)\n",
        "  plt.xlabel(\"False Positive Rate\")\n",
        "  plt.ylabel(\"True Positive Rate\")\n",
        "  plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
        "  plt.legend(loc = \"lower right\")\n",
        "  plt.grid(alpha = 0.7)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "ET26cqXgKCD6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline function\n",
        "def pipeline(train = pd.DataFrame, test = pd.DataFrame, preprocessing_functions = tuple, mindf = int, model = str, k = int, classifier = str, regularization = \"L1\") -> float:\n",
        "  \"\"\"\n",
        "  Runs the pipeline for a given set of parameters.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  train : pd.DataFrame\n",
        "    The training set.\n",
        "  test : pd.DataFrame\n",
        "    The testing set.\n",
        "  preprocessing_functions : tuple\n",
        "    The tuple of preprocessing functions to apply.\n",
        "  mindf : int\n",
        "    The minimum document frequency.\n",
        "  model : str\n",
        "    The model to use.\n",
        "  k : int\n",
        "    The number of components to use.\n",
        "  classifier : str\n",
        "    The classifier to use.\n",
        "  regularization : str\n",
        "    The regularization to use. Used only for logistic regression.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  accuracy : float\n",
        "    The accuracy of the model.\n",
        "  best_param : float\n",
        "    The gamma parameter of the model. Used for SVM and logistic regression.\n",
        "  \"\"\"\n",
        "\n",
        "  ### Loading Data\n",
        "  # Preprocessing\n",
        "  preprocessing_functions = list(preprocessing_functions)\n",
        "  X_train = preprocessing(train, preprocessing_functions)\n",
        "  X_test = preprocessing(test, preprocessing_functions)\n",
        "\n",
        "  ### Feature Extraction\n",
        "  # Convert to TF-IDF Matrix\n",
        "  count_vect = CountVectorizer(stop_words = 'english', min_df = mindf)\n",
        "  tfidf_transformer = TfidfTransformer()\n",
        "  X_train_counts = count_vect.fit_transform(X_train['full_text'])\n",
        "  X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "  X_test_counts = count_vect.transform(X_test['full_text'])\n",
        "  X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
        "\n",
        "  ### Dimensionality Reduction\n",
        "  # LSI Model\n",
        "  if model == \"LSI\":\n",
        "    svd = TruncatedSVD(n_components = k, random_state = 42)\n",
        "    X_train_reduced = svd.fit_transform(X_train_tfidf)\n",
        "    X_test_reduced = svd.transform(X_test_tfidf)\n",
        "  # NMF Model\n",
        "  elif model == \"NMF\":\n",
        "    nmf = NMF(n_components = k, init = 'random', random_state = 42)\n",
        "    W_train = nmf.fit_transform(X_train_tfidf)\n",
        "    H = nmf.components_\n",
        "    X_train_reduced = W_train\n",
        "    W_test = nmf.transform(X_test_tfidf)\n",
        "    X_test_reduced = W_test\n",
        "  else:\n",
        "    raise ValueError(\"Invalid model name\")\n",
        "\n",
        "  ### Classifier\n",
        "\n",
        "  # Parameter grid for SVM and Logistic Regression\n",
        "  param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000]}\n",
        "  best_param = None # Default best gamma to none\n",
        "\n",
        "  # SVM Model\n",
        "  if classifier == \"SVM\":\n",
        "    # Perform 5-fold cross validation to choose best gamma\n",
        "    model = LinearSVC(random_state = 42)\n",
        "\n",
        "    # Perform grid search to find best parameter\n",
        "    grid_search = GridSearchCV(model, param_grid, cv = 5, scoring = 'accuracy')\n",
        "    grid_search.fit(X_train_reduced, train['root_label'])\n",
        "\n",
        "    # Get best parameter\n",
        "    best_param = grid_search.best_params_['C']\n",
        "\n",
        "    # Fit model using best parameter\n",
        "    best_model = LinearSVC(C = best_param, random_state = 42)\n",
        "    best_model.fit(X_train_reduced, train['root_label'])\n",
        "    y_pred_best = best_model.fit(X_train_reduced, train['root_label']).predict(X_test_reduced)\n",
        "    y_pred_best_svm = y_pred_best # Keep for McNemar's test\n",
        "    y_pred_best_prob = best_model.fit(X_train_reduced, train['root_label']).decision_function(X_test_reduced)\n",
        "\n",
        "    # Get accuracy\n",
        "    accuracy = accuracy_score(test['root_label'], y_pred_best)\n",
        "\n",
        "  # Logistic Regression Model\n",
        "  elif classifier == \"Logistic Regression\":\n",
        "    if regularization == \"L1\":\n",
        "      # L1 regularization\n",
        "      model = LogisticRegression(random_state = 42, penalty = 'l1', solver = 'liblinear')\n",
        "      grid_search = GridSearchCV(model, param_grid, cv = 5, scoring = 'accuracy')\n",
        "      grid_search.fit(X_train_reduced, train['root_label'])\n",
        "\n",
        "      # Extract best parameter\n",
        "      best_param = grid_search.best_params_['C']\n",
        "\n",
        "      # Fit model using best parameter\n",
        "      best_model = LogisticRegression(C = best_param, random_state = 42, penalty = 'l1', solver = 'liblinear')\n",
        "      best_model.fit(X_train_reduced, train['root_label'])\n",
        "      y_pred_best = best_model.fit(X_train_reduced, train['root_label']).predict(X_test_reduced)\n",
        "      y_pred_best_prob = best_model.fit(X_train_reduced, train['root_label']).predict_proba(X_test_reduced)[:, 1]\n",
        "\n",
        "      # Get accuracy\n",
        "      accuracy = accuracy_score(test['root_label'], y_pred_best)\n",
        "\n",
        "    elif regularization == \"L2\":\n",
        "      # L2 regularization\n",
        "      model = LogisticRegression(random_state = 42, penalty = 'l2')\n",
        "      grid_search = GridSearchCV(model, param_grid, cv = 5, scoring = 'accuracy')\n",
        "      grid_search.fit(X_train_reduced, train['root_label'])\n",
        "\n",
        "      # Extract best parameter\n",
        "      best_param = grid_search.best_params_['C']\n",
        "\n",
        "      # Fit model using best parameter\n",
        "      best_model = LogisticRegression(C = best_param, random_state = 42, penalty = 'l2')\n",
        "      best_model.fit(X_train_reduced, train['root_label'])\n",
        "      y_pred_best = best_model.fit(X_train_reduced, train['root_label']).predict(X_test_reduced)\n",
        "      y_pred_best_lr = y_pred_best # Keep for McNemar's test\n",
        "      y_pred_best_prob = best_model.fit(X_train_reduced, train['root_label']).predict_proba(X_test_reduced)[:, 1]\n",
        "\n",
        "      # Get accuracy\n",
        "      accuracy = accuracy_score(test['root_label'], y_pred_best)\n",
        "\n",
        "    else:\n",
        "      raise ValueError(\"Invalid regularization name\")\n",
        "\n",
        "  # Naive Bayes Classifier\n",
        "  elif classifier == \"Naive Bayes\":\n",
        "    model = GaussianNB()\n",
        "    model.fit(X_train_reduced, train['root_label'])\n",
        "    y_pred = model.predict(X_test_reduced)\n",
        "    y_pred_prob = model.predict_proba(X_test_reduced)[:, 1]\n",
        "\n",
        "    # Get accuracy\n",
        "    accuracy = accuracy_score(test['root_label'], y_pred)\n",
        "\n",
        "  return accuracy, best_param"
      ],
      "metadata": {
        "id": "PiqS6nm8KlKB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Global variables\n",
        "df = pd.read_csv(\"Project1-ClassificationDataset.csv\")\n",
        "training, testing = train_test_split(df[[\"full_text\", \"root_label\"]], test_size = 0.2)\n",
        "\n",
        "# Test arguments\n",
        "train = training\n",
        "test = testing\n",
        "preprocessing_functions = (clean, remove_numbers, remove_punctuation)\n",
        "mindf = 3\n",
        "model = \"LSI\"\n",
        "model = \"NMF\"\n",
        "k = 5\n",
        "# classifier = \"Logistic Regression\"\n",
        "# classifier = \"Logistic Regression\"\n",
        "classifier = \"Naive Bayes\"\n",
        "regularization = \"L1\"\n",
        "# regularization = \"L2\"\n",
        "\n",
        "pipeline(train, test, preprocessing_functions, mindf, model, k, classifier, regularization)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5ADOB60LcIx",
        "outputId": "85f6e567-98a5-4a24-f066-6c55a1ca7797"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8663793103448276, None)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let combinations be keys and accuracies (and regularization if applicable) be values\n",
        "combinations = []\n",
        "accuracy_values = []\n",
        "\n",
        "# Hyperparameters for pipeline comparison\n",
        "# Feature extraction\n",
        "mindfs = [2, 3, 4, 5]\n",
        "preprocessing_functions_list = [(clean, remove_numbers, remove_punctuation, lemmatize), (clean, remove_numbers, remove_punctuation, stemming)]\n",
        "# preprocessing_functions_list = [(clean, remove_numbers, remove_punctuation)]\n",
        "\n",
        "# Dimensionality Reduction\n",
        "models = [\"LSI\", \"NMF\"]\n",
        "components = [5, 30, 100]\n",
        "\n",
        "# Classifier\n",
        "classifiers = [\"SVM\", \"Logistic Regression\"]\n",
        "regularizations = [\"L1\", \"L2\"]\n",
        "\n",
        "for mindf in mindfs:\n",
        "  for preprocessing_functions in preprocessing_functions_list:\n",
        "    for model in models:\n",
        "      for k in components:\n",
        "        for classifier in classifiers:\n",
        "          if classifier == \"Logistic Regression\":\n",
        "            for regularization in regularizations:\n",
        "              combinations.append((mindf, preprocessing_functions, model, k, classifier, regularization))\n",
        "          else:\n",
        "            combinations.append((mindf, preprocessing_functions, model, k, classifier))\n",
        "\n",
        "for combination in tqdm(combinations, desc = \"Processing combinations\"):\n",
        "  mindf = combination[0]\n",
        "  preprocessing_functions = combination[1]\n",
        "  model = combination[2]\n",
        "  k = combination[3]\n",
        "  classifier = combination[4]\n",
        "  if classifier == \"Logistic Regression\":\n",
        "    regularization = combination[5]\n",
        "    accuracy_values.append(pipeline(train, test, preprocessing_functions, mindf, model, k, classifier, regularization))\n",
        "  else:\n",
        "    accuracy_values.append(pipeline(train, test, preprocessing_functions, mindf, model, k, classifier))\n",
        "\n",
        "# Dictionary to store combinations and accuracy/regularization\n",
        "combinations_accuracy = {}\n",
        "\n",
        "# Add key-value pairs dynamically in a loop\n",
        "for key, value in zip(combinations, accuracy_values):\n",
        "    combinations_accuracy[key] = value\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geAXV4hNM6hA",
        "outputId": "0f17695a-df4d-4a05-f31b-5fc781306d8f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing combinations:  10%|█         | 15/144 [27:15<4:13:12, 117.77s/it]/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "Processing combinations:  23%|██▎       | 33/144 [50:45<1:38:50, 53.43s/it]/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "Processing combinations:  29%|██▉       | 42/144 [1:09:38<2:55:24, 103.18s/it]/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "Processing combinations:  35%|███▌      | 51/144 [1:25:35<2:44:07, 105.89s/it]/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "Processing combinations:  42%|████▏     | 60/144 [1:39:08<1:10:47, 50.56s/it]/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "Processing combinations:  48%|████▊     | 69/144 [1:45:29<53:28, 42.77s/it]/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "Processing combinations:  54%|█████▍    | 78/144 [2:02:14<1:51:34, 101.44s/it]/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "Processing combinations:  60%|██████    | 87/144 [2:17:53<1:39:38, 104.89s/it]/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "Processing combinations:  67%|██████▋   | 96/144 [2:29:59<38:17, 47.87s/it]/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "Processing combinations:  73%|███████▎  | 105/144 [2:36:00<26:59, 41.51s/it]/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "Processing combinations:  85%|████████▌ | 123/144 [3:07:25<37:57, 108.45s/it]/usr/local/lib/python3.11/dist-packages/sklearn/decomposition/_nmf.py:1741: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "Processing combinations:  86%|████████▌ | 124/144 [3:10:44<45:12, 135.64s/it]/usr/local/lib/python3.11/dist-packages/sklearn/decomposition/_nmf.py:1741: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
            "  warnings.warn(\n",
            "Processing combinations:  87%|████████▋ | 125/144 [3:14:00<48:43, 153.87s/it]/usr/local/lib/python3.11/dist-packages/sklearn/decomposition/_nmf.py:1741: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
            "  warnings.warn(\n",
            "Processing combinations:  98%|█████████▊| 141/144 [3:26:37<02:07, 42.50s/it]/usr/local/lib/python3.11/dist-packages/sklearn/decomposition/_nmf.py:1741: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "Processing combinations:  99%|█████████▊| 142/144 [3:28:43<02:15, 67.55s/it]/usr/local/lib/python3.11/dist-packages/sklearn/decomposition/_nmf.py:1741: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
            "  warnings.warn(\n",
            "Processing combinations:  99%|█████████▉| 143/144 [3:30:51<01:25, 85.49s/it]/usr/local/lib/python3.11/dist-packages/sklearn/decomposition/_nmf.py:1741: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
            "  warnings.warn(\n",
            "Processing combinations: 100%|██████████| 144/144 [3:33:04<00:00, 88.78s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store combinations and accuracies/regularization in a txt file (above code takes ~3.5 hours to run)\n",
        "with open(\"accuracy_values.txt\", \"w\") as f:\n",
        "  f.write(str(accuracy_values))"
      ],
      "metadata": {
        "id": "ydkGluR4xjHZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"combinations.txt\", \"w\") as f:\n",
        "  f.write(str(combinations))"
      ],
      "metadata": {
        "id": "9VmtDkO5yTwJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store combinations and accuracy/regularization\n",
        "combinations_accuracy = {}\n",
        "\n",
        "# Add key-value pairs dynamically in a loop\n",
        "for key, value in zip(combinations, accuracy_values):\n",
        "    combinations_accuracy[key] = value"
      ],
      "metadata": {
        "id": "C8JHsMZSA0QH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store dictionary\n",
        "with open(\"combinations_accuracy.txt\", \"w\") as f:\n",
        "  f.write(str(combinations_accuracy))"
      ],
      "metadata": {
        "id": "myze_7iqy2v5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combinations with issues:\n",
        "# 15, 33, 42, 51, 60, 69, 78, 87, 96, 105, 123, 124, 125, 141, 142, 143"
      ],
      "metadata": {
        "id": "vCPaag8X8zTz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}